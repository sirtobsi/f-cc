## Pull Request Template

**Candidate Name:** [Your Name]  
**Contact:** [Email]  
**Date Submitted:** [Date]

---

### âœ… Checklist

- [ ] I have implemented at least partial functionality for all three functions
- [ ] I have run the exposed tests locally (`pytest tests/test_exposed.py -v`)
- [ ] I have completed NOTES.md with my assumptions and design decisions
- [ ] I have not modified `src/data_simulator.py` or test files
- [ ] My code follows Python best practices (PEP 8)

---

### ğŸ“Š Test Results

**Exposed Tests:**
- Tests Passed: [X/Y]
- Tests Failed: [X/Y]
- Test Pass Rate: [X%]

**Commands I ran:**
```bash
pytest tests/test_exposed.py -v
```

---

### ğŸ¯ Implementation Summary

**Time Spent:** Approximately [X] hours

**What I Completed:**
- [ ] `ingest_data()` - [Brief status: fully implemented / partially implemented / basic only]
- [ ] `detect_anomalies()` - [Brief status]
- [ ] `summarize_metrics()` - [Brief status]

**Key Features:**
- [Feature 1: e.g., "Robust duplicate detection using timestamp+sensor+value"]
- [Feature 2: e.g., "Z-score anomaly detection with configurable threshold"]
- [Feature 3: e.g., "Comprehensive quality metrics including null rates"]

---

### ğŸ¤” Design Highlights

**Most Proud Of:**
[What implementation detail or approach you're most proud of]

**Biggest Challenge:**
[What was most challenging and how you approached it]

**If I Had More Time:**
[Top 2-3 things you would improve/add]

---

### ğŸ“ Notes

**Known Limitations:**
- [Limitation 1]
- [Limitation 2]

**Assumptions:**
- [Key assumption 1]
- [Key assumption 2]

**Questions for Reviewers:**
- [Question 1]
- [Question 2]

---

### ğŸ“š Additional Context

[Any other information you think reviewers should know]

---

**Thank you for reviewing my submission!** I'm excited to discuss my approach and learn from your feedback.
